{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = loadmat('uft_flight07.mat', variable_names=('lowT_av', 'upT_av', 'lwc1V_av'))\n",
    "\n",
    "# with open(\"data.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(data, f)\n",
    "\n",
    "with open(\"data.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOW =  275000\n",
    "HIGH = 300000\n",
    "\n",
    "Y1 = data['lowT_av'].squeeze()\n",
    "Y2 = data['upT_av'].squeeze()\n",
    "LWC = data['lwc1V_av']\n",
    "X = np.arange(Y1.shape[0]) / 100.\n",
    "\n",
    "X_cut = X[LOW:HIGH]\n",
    "Y1_cut = Y1[LOW:HIGH]\n",
    "Y2_cut = Y2[LOW:HIGH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_heuristic(data):\n",
    "    # Decent threshold: 0.01\n",
    "    return data.max(axis=1) - data.min(axis=1)\n",
    "\n",
    "\n",
    "def base_mean_heuristic(data):\n",
    "    # Decent threshold: 0.007\n",
    "    return data.max(axis=1) - data.mean(axis=1)\n",
    "\n",
    "def base_median_heuristic(data):\n",
    "    return data.max(axis=1) - np.median(data, axis=1)\n",
    "\n",
    "\n",
    "def std_small_heuristic(data):\n",
    "    # Decent threshold: 5\n",
    "    return (data.max(axis=1) - data.min(axis=1)) / data.std(axis=1)\n",
    "\n",
    "\n",
    "def std_wide_heuristic(data):\n",
    "    N = data.shape[1]\n",
    "    mid = int((N - 1) / 2)\n",
    "    data = data / data.std(axis=1, keepdims=True)\n",
    "    return (data[:,mid-2:mid+3].max(axis=1) - data[:,mid-2:mid+3].min(axis=1))\n",
    "\n",
    "def std_new_heuristic(data):\n",
    "    N = data.shape[1]\n",
    "    mid = (N - 1) / 2\n",
    "    data = data / data.std(axis=1, keepdims=True)\n",
    "    return (data[:,mid:N+1] - data[:,N-2:N+3].min(axis=1))\n",
    "\n",
    "\n",
    "def rolling_window(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "\n",
    "def detect_jumps(data, size=5, threshold=.01, func=baseline_heuristic):\n",
    "    assert size % 2 # Only odd sizes, for now\n",
    "    pad = size // 2\n",
    "    \n",
    "    strided_data = rolling_window(data, size)\n",
    "    #diff = strided_data.max(axis=1) - strided_data.min(axis=1)\n",
    "    result = func(strided_data)\n",
    "    result = np.hstack((np.zeros(pad), result, np.zeros(pad)))\n",
    "    return result > threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4536,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jumps = detect_jumps(Y1_cut, 7, .007, base_median_heuristic)\n",
    "np.where(jumps)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18,4)\n",
    "\n",
    "WIDTH = 0.5\n",
    "\n",
    "#jumps = detect_jumps(Y1_cut, 9, 3.75, std_wide_heuristic)\n",
    "#jumps = detect_jumps(Y1_cut, 5, .005, base_mean_heuristic)\n",
    "\n",
    "highlight = np.where(jumps)[0] / 100.\n",
    "highlight += LOW / 100.\n",
    "\n",
    "\n",
    "plt.vlines(highlight, 13.8, 14.6, alpha=.25, linewidth=2.5, colors='r')\n",
    "plt.plot(X_cut, Y1_cut, linewidth=WIDTH)\n",
    "#plt.plot(X_cut, Y2_cut, linewidth=WIDTH)\n",
    "#plt.plot(X[LOW:HIGH], 20*LWC[LOW:HIGH])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(X_cut, Y1_cut, linewidth=WIDTH)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WINDOW = 21\n",
    "PAD = WINDOW // 2\n",
    "\n",
    "rolled = rolling_window(Y1_cut, WINDOW).mean(1)\n",
    "rolled = np.hstack((np.ones((PAD,)) * rolled[:PAD].mean(), rolled, np.ones((PAD,)) * rolled[-PAD:].mean()))\n",
    "\n",
    "#plt.plot(X_cut, Y1_cut - rolled, linewidth=0.5)\n",
    "plt.plot(X_cut, Y1_cut);plt.plot(X_cut, rolled)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global normalization - probably redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.302825324832844"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1_cut.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y1_norm = (Y1 - Y1.mean()) / Y1.std()\n",
    "\n",
    "WINDOW = 21\n",
    "PAD = WINDOW // 2\n",
    "\n",
    "#rolled = rolling_window(Y1_norm, WINDOW).mean(1) # median?\n",
    "rolled = np.median(rolling_window(Y1_norm, WINDOW), axis=1)\n",
    "rolled = np.hstack((np.ones((PAD,)) * rolled[:PAD].mean(), rolled, np.ones((PAD,)) * rolled[-PAD:].mean()))\n",
    "\n",
    "#plt.plot(X, Y1_norm - rolled, linewidth=0.5)\n",
    "plt.plot(X, Y1_norm);plt.plot(X, rolled)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do:\n",
    "\n",
    "0. Estimate the optimal threshold value, maybe via a purely statistical analysis (i.e. fraction of all points that are marked as jumps)\n",
    "\n",
    "0. Estimate the optimal window (other than 5 - maybe)\n",
    "\n",
    "0. Try to make it more robust to excessive noise (divide the diff term by std?)\n",
    "\n",
    "0. Substract linear baseline\n",
    "\n",
    "0. More sophisticated algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas:\n",
    "\n",
    "Use the smoothed-out line as a baseline or something.\n",
    "\n",
    "Measure the maximum distance between baseline and actual series\n",
    "\n",
    "On a slightly larger window, fourier and defourier (filtering)? (or other denoising)\n",
    "\n",
    "Change mean to median, std to median absolute deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General idea:\n",
    "\n",
    "Get a smoothed-out version of the series, measure distance between it and original"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
